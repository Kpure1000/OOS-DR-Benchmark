{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplot inline\n",
    "import numpy as np\n",
    "from numpy.random import mtrand\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from scipy.spatial.transform import Rotation\n",
    "import h5py as h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_axis_aligned_plane_cluster(n_samples, ax1_center, ax1_range, ax2_center, ax2_range, ax3_value=0.0, noise=None, axes='yz', seed=None, gaussian=True):\n",
    "    generator = mtrand.RandomState(seed)\n",
    "    if gaussian:\n",
    "        ax1 = generator.normal(ax1_center, ax1_range, n_samples)\n",
    "        ax2 = generator.normal(ax2_center, ax2_range, n_samples)\n",
    "    else:\n",
    "        ax1 = generator.uniform(ax1_center - ax1_range, ax1_center + ax1_range, n_samples)\n",
    "        ax2 = generator.uniform(ax2_center - ax2_range, ax2_center + ax2_range, n_samples)\n",
    "    X = np.zeros(shape=(n_samples, 3), dtype=np.float64)\n",
    "    _axes = axes.lower()\n",
    "    if _axes == 'yz':\n",
    "        X[:, 0], X[:, 1], X[:, 2] = ax3_value, ax1, ax2\n",
    "    elif _axes == 'xz':\n",
    "        X[:, 0], X[:, 1], X[:, 2] = ax1, ax3_value, ax2\n",
    "    elif _axes == 'xy':\n",
    "        X[:, 0], X[:, 1], X[:, 2] = ax1, ax2, ax3_value\n",
    "    else:\n",
    "        raise ValueError(f'Invalid axes \"{_axes}\"')\n",
    "    if noise is not None:\n",
    "        X += noise * generator.standard_normal(size=(n_samples, 3))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make S-Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_s_curve_clustered(n_samples, t_center, t_range, y_center, y_range, noise=None, seed=None, gaussian=True):\n",
    "    generator = mtrand.RandomState(seed)\n",
    "    if gaussian:\n",
    "        t = 3 * np.pi * (generator.normal(t_center, t_range, size=(1, n_samples)) - 0.5)\n",
    "        y = 2.0 * generator.normal(y_center, y_range, size=n_samples)\n",
    "    else:\n",
    "        t = 3 * np.pi * (generator.uniform(t_center - t_range, t_center + t_range, size=(1, n_samples)) - 0.5)\n",
    "        y = 2.0 * generator.uniform(y_center - y_range, y_center + y_range, size=n_samples)\n",
    "    X = np.empty(shape=(n_samples, 3), dtype=np.float64)\n",
    "    X[:, 0] = np.sin(t)\n",
    "    X[:, 1] = y\n",
    "    X[:, 2] = np.sign(t) * (np.cos(t) - 1)\n",
    "    X += noise * generator.standard_normal(size=(3, n_samples)).T\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Swiss Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_swiss_roll_clustered(n_samples, t_center, t_range, y_center, y_range, noise=None, seed=None):\n",
    "    generator = mtrand.RandomState(seed)\n",
    "    t = 1.5 * np.pi * (1 + 2 * generator.normal(t_center, t_range, size=n_samples))\n",
    "    y = 10 * generator.normal(y_center, y_range, size=n_samples)\n",
    "    x = t * np.cos(t)\n",
    "    z = t * np.sin(t)\n",
    "    X = np.vstack((x, y, z))\n",
    "    X += noise * generator.standard_normal(size=(3, n_samples))\n",
    "    X*=0.2\n",
    "    X = X.T\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Cylinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cylinder_clustered(n_samples, t_center, t_range, y_center, y_range, noise=None, seed=None, gaussian=False):\n",
    "    generator = mtrand.RandomState(seed)\n",
    "    if gaussian:\n",
    "        t = 2 * np.pi * (generator.normal(t_center, t_range, size=n_samples) - 0.5)\n",
    "        y = 10 * generator.normal(y_center, y_range, size=n_samples)\n",
    "    else:\n",
    "        t = 2 * np.pi * (generator.uniform(t_center - t_range, t_center + t_range, size=n_samples) - 0.5)\n",
    "        y = 10 * generator.uniform(y_center - y_range, y_center + y_range, size=n_samples)\n",
    "    x = np.cos(t)\n",
    "    z = np.sin(t)\n",
    "    X = np.vstack((x, y, z))\n",
    "    X += noise * generator.standard_normal(size=(3, n_samples))\n",
    "    X*=0.2\n",
    "    X = X.T\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prop_data(X, y, name):\n",
    "    with h5.File(f'datasets/synth/{name}_prop.h5', 'w') as f:\n",
    "        gE=f.create_group('E')\n",
    "        gO=f.create_group('O')\n",
    "        props=[0.9, 0.7, 0.5, 0.3]\n",
    "        for i,prop in enumerate(props):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=prop, random_state=i, stratify=y)\n",
    "            gE.create_dataset(f'X{i}', data=X_train)\n",
    "            gE.create_dataset(f'y{i}', data=y_train)\n",
    "            gO.create_dataset(f'X{i}', data=X_test)\n",
    "            gO.create_dataset(f'y{i}', data=y_test)\n",
    "\n",
    "def save_dist_data(X_train, X_test, y_train, y_test, name):\n",
    "    with h5.File(f'datasets/synth/{name}_dist.h5', 'w') as f:\n",
    "        gE=f.create_group('E')\n",
    "        gO=f.create_group('O')\n",
    "        gE.create_dataset('X0', data=X_train)\n",
    "        gE.create_dataset('y0', data=y_train)\n",
    "        gO.create_dataset('X0', data=X_test)\n",
    "        gO.create_dataset('y0', data=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plane * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters_p = [\n",
    "#     {'n_samples':200, 'ax1_center':0.0, 'ax1_range':0.15, 'ax2_center':0.0, 'ax2_range':0.15, 'noise':0.01, 'ax3_value':0, 'axes':'yz'},\n",
    "#     {'n_samples':200, 'ax1_center':0.0, 'ax1_range':0.15, 'ax2_center':1.0, 'ax2_range':0.15, 'noise':0.01, 'ax3_value':0, 'axes':'yz'},\n",
    "#     {'n_samples':200, 'ax1_center':0.5, 'ax1_range':0.15, 'ax2_center':0.5, 'ax2_range':0.15, 'noise':0.01, 'ax3_value':0, 'axes':'yz'},\n",
    "#     {'n_samples':200, 'ax1_center':1.0, 'ax1_range':0.15, 'ax2_center':0.0, 'ax2_range':0.15, 'noise':0.01, 'ax3_value':0, 'axes':'yz'},\n",
    "#     {'n_samples':200, 'ax1_center':1.0, 'ax1_range':0.15, 'ax2_center':1.0, 'ax2_range':0.15, 'noise':0.01, 'ax3_value':0, 'axes':'yz'},\n",
    "# ]\n",
    "\n",
    "clusters_p = [\n",
    "    {'n_samples':350, 'ax1_center':0.0, 'ax1_range':1.2, 'ax2_center':-1.0, 'ax2_range':0.3, 'noise':0.01, 'ax3_value':0.0, 'axes':'xz', 'gaussian': False},\n",
    "    {'n_samples':350, 'ax1_center':0.0, 'ax1_range':1.2, 'ax2_center': 0.0, 'ax2_range':0.3, 'noise':0.01, 'ax3_value':0.0, 'axes':'xz', 'gaussian': False},\n",
    "    {'n_samples':350, 'ax1_center':0.0, 'ax1_range':1.2, 'ax2_center': 1.0, 'ax2_range':0.3, 'noise':0.01, 'ax3_value':0.0, 'axes':'xz', 'gaussian': False},\n",
    "]\n",
    "\n",
    "n_samples_single = sum([c['n_samples'] for c in clusters_p])\n",
    "X_p=[]\n",
    "y_p=[]\n",
    "clusters_ps = clusters_p + clusters_p + clusters_p\n",
    "for cluster in clusters_ps:\n",
    "    Xp = make_axis_aligned_plane_cluster(**cluster)\n",
    "    X_p.append(Xp)\n",
    "    y_p.append(np.ones(Xp.shape[0]) * len(X_p))\n",
    "\n",
    "X = np.vstack(X_p)\n",
    "y = np.concatenate(y_p)\n",
    "\n",
    "X1 = X[:n_samples_single]\n",
    "y1 = y[:n_samples_single]\n",
    "\n",
    "X2 = X[n_samples_single:n_samples_single * 2]\n",
    "y2 = y[n_samples_single:n_samples_single * 2]\n",
    "\n",
    "X3 = X[n_samples_single * 2:]\n",
    "y3 = y[n_samples_single * 2:]\n",
    "\n",
    "X1 = Rotation.from_euler('xz', [90,90], degrees=True).apply(X1)\n",
    "# X1[:, [0, 2]] += np.array([-0.1, -0.5])\n",
    "\n",
    "X2 = Rotation.from_euler('zx', [90,90], degrees=True).apply(X2)\n",
    "\n",
    "# X3 = Rotation.from_euler('z', 90, degrees=True).apply(X3)\n",
    "# X3[:, [0, 2]] += np.array([0.1, 0.5])\n",
    "\n",
    "X = np.vstack([X1, X2, X3])\n",
    "y = np.concatenate([y1, y2, y3])\n",
    "save_prop_data(X, y, 'syn1')\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, train_size=0.7, random_state=100, stratify=y1)\n",
    "X1_test[:, [0, 2]] += [0.5, 0.1]\n",
    "X1_test[:, [1, 2]] *= 1.2\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size=0.7, random_state=100, stratify=y2)\n",
    "X2_test[:, [1, 2]] += [0.5, 0.5]\n",
    "X2_test[:, [1, 2]] *= 0.8\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, train_size=0.7, random_state=100, stratify=y3)\n",
    "X3_test[:, [0, 2]] += [-0.5,-0.1]\n",
    "X3_test[:, [1, 2]] *= 1.2\n",
    "X_train = np.vstack([X1_train, X2_train, X3_train])\n",
    "X_test = np.vstack([X1_test, X2_test, X3_test])\n",
    "y_train = np.concatenate([y1_train, y2_train, y3_train])\n",
    "y_test = np.concatenate([y1_test, y2_test, y3_test])\n",
    "\n",
    "save_dist_data(X_train, X_test, y_train, y_test, 'syn1')\n",
    "\n",
    "fig = plt.figure()\n",
    "plot = fig.add_subplot(111, projection='3d')\n",
    "plot.scatter(X_train[:, 0], X_train[:, 1], X_train[:, 2], c='gray', s=1)\n",
    "plot.scatter(X_test[:, 0], X_test[:, 1], X_test[:, 2], c='red', s=1)\n",
    "plt.show()\n",
    "\n",
    "fig=plt.figure()\n",
    "plot = fig.add_subplot(111, projection='3d')\n",
    "plot.scatter(X[:,0], X[:,1], X[:,2], c=y, s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swiss Roll + Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s=[]\n",
    "y_s=[]\n",
    "\n",
    "clusters_s = [\n",
    "    {'n_samples':200, 't_center':0.1, 't_range':0.05, 'y_center': 0.0, 'y_range':0.3, 'noise':0.01},\n",
    "    {'n_samples':200, 't_center':0.1, 't_range':0.05, 'y_center': 1.0, 'y_range':0.3, 'noise':0.01},\n",
    "    {'n_samples':200, 't_center':0.3, 't_range':0.05, 'y_center': 0.0, 'y_range':0.3, 'noise':0.01},\n",
    "    {'n_samples':200, 't_center':0.3, 't_range':0.05, 'y_center': 1.0, 'y_range':0.3, 'noise':0.01},\n",
    "    {'n_samples':200, 't_center':0.5, 't_range':0.05, 'y_center': 0.0, 'y_range':0.3, 'noise':0.01},\n",
    "    {'n_samples':200, 't_center':0.5, 't_range':0.05, 'y_center': 1.0, 'y_range':0.3, 'noise':0.01},\n",
    "    {'n_samples':200, 't_center':0.7, 't_range':0.05, 'y_center': 0.0, 'y_range':0.3, 'noise':0.01},\n",
    "    {'n_samples':200, 't_center':0.7, 't_range':0.05, 'y_center': 1.0, 'y_range':0.3, 'noise':0.01},\n",
    "    {'n_samples':200, 't_center':0.9, 't_range':0.05, 'y_center': 0.0, 'y_range':0.3, 'noise':0.01},\n",
    "    {'n_samples':200, 't_center':0.9, 't_range':0.05, 'y_center': 1.0, 'y_range':0.3, 'noise':0.01},\n",
    "]\n",
    "for cluster in clusters_s:\n",
    "    Xs = make_swiss_roll_clustered(**cluster)\n",
    "    X_s.append(Xs)\n",
    "    y_s.append(np.ones(Xs.shape[0]) * len(X_s))\n",
    "X1=np.vstack(X_s)\n",
    "y1=np.concatenate(y_s)\n",
    "\n",
    "clusters_p = [\n",
    "    {'n_samples':300, 'ax1_center':0.0, 'ax1_range':1.2, 'ax2_center':-1.0, 'ax2_range':0.4, 'noise':0.02, 'ax3_value':0.6, 'axes':'xz', 'gaussian': False},\n",
    "    {'n_samples':300, 'ax1_center':0.0, 'ax1_range':1.2, 'ax2_center': 0.0, 'ax2_range':0.4, 'noise':0.02, 'ax3_value':0.6, 'axes':'xz', 'gaussian': False},\n",
    "    {'n_samples':300, 'ax1_center':0.0, 'ax1_range':1.2, 'ax2_center': 1.0, 'ax2_range':0.4, 'noise':0.02, 'ax3_value':0.6, 'axes':'xz', 'gaussian': False},\n",
    "]\n",
    "n_samples_single = sum([c['n_samples'] for c in clusters_p])\n",
    "X_p=[]\n",
    "y_p=[]\n",
    "clusters_ps = clusters_p\n",
    "for cluster in clusters_ps:\n",
    "    Xp = make_axis_aligned_plane_cluster(**cluster)\n",
    "    X_p.append(Xp)\n",
    "    y_p.append(np.ones(Xp.shape[0]) * (len(X_s) + len(X_p)))\n",
    "\n",
    "Xp=np.vstack(X_p)\n",
    "yp=np.concatenate(y_p)\n",
    "\n",
    "X2=Xp[:n_samples_single]\n",
    "X2[:, [0,2]] *= [2.0]\n",
    "y2=yp[:n_samples_single]\n",
    "\n",
    "X = np.vstack([X1, X2])\n",
    "y = np.concatenate([y1, y2])\n",
    "\n",
    "save_prop_data(X, y, 'syn2')\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, train_size=0.7, random_state=100, stratify=y1)\n",
    "X1_test[:, 1] += 2\n",
    "X1_test[:, [1, 2]] *= 0.9\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size=0.7, random_state=100, stratify=y2)\n",
    "# X2_test[:, [1, 2]] += [0.5, 0.5]\n",
    "X2_test[:, [1, 2]] *= 0.8\n",
    "\n",
    "X_train = np.vstack([X1_train, X2_train])\n",
    "X_test = np.vstack([X1_test, X2_test])\n",
    "y_train = np.concatenate([y1_train, y2_train])\n",
    "y_test = np.concatenate([y1_test, y2_test])\n",
    "\n",
    "save_dist_data(X_train, X_test, y_train, y_test, 'syn2')\n",
    "\n",
    "fig = plt.figure()\n",
    "plot = fig.add_subplot(111, projection='3d')\n",
    "plot.scatter(X_train[:, 0], X_train[:, 1], X_train[:, 2], c='gray', s=1)\n",
    "plot.scatter(X_test[:, 0], X_test[:, 1], X_test[:, 2], c='red', s=1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "plot = fig.add_subplot(111, projection='3d')\n",
    "plot.scatter(X[:,0], X[:,1], X[:,2], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SwissRoll * 2 + Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clusters_s = [\n",
    "    {'n_samples':200, 't_center':0.2 , 't_range':0.07, 'y_center':-0.5, 'y_range':0.3, 'noise':0.02},\n",
    "    {'n_samples':200, 't_center':0.25, 't_range':0.07, 'y_center': 0.5, 'y_range':0.3, 'noise':0.02},\n",
    "    {'n_samples':200, 't_center':0.5 , 't_range':0.07, 'y_center':-0.5, 'y_range':0.3, 'noise':0.02},\n",
    "    {'n_samples':200, 't_center':0.55, 't_range':0.07, 'y_center': 0.5, 'y_range':0.3, 'noise':0.02},\n",
    "    {'n_samples':200, 't_center':0.8 , 't_range':0.07, 'y_center':-0.5, 'y_range':0.3, 'noise':0.02},\n",
    "    {'n_samples':200, 't_center':0.75, 't_range':0.07, 'y_center': 0.5, 'y_range':0.3, 'noise':0.02},\n",
    "]\n",
    "X_1=[]\n",
    "y_1=[]\n",
    "for cluster in clusters_s:\n",
    "    Xs = make_swiss_roll_clustered(**cluster)\n",
    "    X_1.append(Xs)\n",
    "    y_1.append(np.ones(Xs.shape[0]) * len(X_1))\n",
    "\n",
    "X1=np.vstack(X_1)\n",
    "# X1=Rotation.from_euler('xy', [180, 90], degrees=True).apply(X1)\n",
    "X1[:, 0] += -3.0\n",
    "y1=np.concatenate(y_1)\n",
    "\n",
    "X_2=[]\n",
    "y_2=[]\n",
    "for cluster in clusters_s:\n",
    "    Xs = make_swiss_roll_clustered(**cluster)\n",
    "    X_2.append(Xs)\n",
    "    y_2.append(np.ones(Xs.shape[0]) * (len(X_2) + len(X_1)))\n",
    "\n",
    "X2 = np.vstack(X_2)\n",
    "X2=Rotation.from_euler('z', 180, degrees=True).apply(X2)\n",
    "X2[:, 0] += 3.0\n",
    "y2 = np.concatenate(y_2)\n",
    "\n",
    "clusters_s = [\n",
    "    {'n_samples':300, 'ax1_center':0.0, 'ax1_range':2.5, 'ax2_center':-1.0, 'ax2_range':0.4, 'noise':0.02, 'ax3_value':0.0, 'axes':'xz', 'gaussian': False},\n",
    "    {'n_samples':300, 'ax1_center':0.0, 'ax1_range':2.5, 'ax2_center': 0.0, 'ax2_range':0.4, 'noise':0.02, 'ax3_value':0.0, 'axes':'xz', 'gaussian': False},\n",
    "    {'n_samples':300, 'ax1_center':0.0, 'ax1_range':2.5, 'ax2_center': 1.0, 'ax2_range':0.4, 'noise':0.02, 'ax3_value':0.0, 'axes':'xz', 'gaussian': False},\n",
    "]\n",
    "\n",
    "X_3=[]\n",
    "y_3=[]\n",
    "for cluster in clusters_s:\n",
    "    Xs = make_axis_aligned_plane_cluster(**cluster)\n",
    "    \n",
    "    X_3.append(Xs)\n",
    "    y_3.append(np.ones(Xs.shape[0]) * (len(X_3) + len(X_2) + len(X_1)))\n",
    "\n",
    "X3 = np.vstack(X_3)\n",
    "# X3=Rotation.from_euler('z', 90, degrees=True).apply(X3)\n",
    "X3[:, [0,2]] *= 2\n",
    "y3 = np.concatenate(y_3)\n",
    "\n",
    "X=np.vstack([X1, X2, X3])\n",
    "y=np.concatenate([y1, y2, y3])\n",
    "\n",
    "save_prop_data(X, y, 'syn3')\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, train_size=0.7, random_state=100, stratify=y1)\n",
    "X1_test[:, 1] *= 0.7\n",
    "X1_test[:, [1, 2]] += [ 2.0, -0.1]\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size=0.7, random_state=100, stratify=y2)\n",
    "X2_test[:, 1] *= 1.3\n",
    "X2_test[:, [1, 2]] += [-2.0, -0.1]\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, train_size=0.7, random_state=100, stratify=y3)\n",
    "# X3_test[:, [0, 2]] += [-0.3,-1]\n",
    "X3_test[:, [1, 2]] *= 0.7\n",
    "X_train = np.vstack([X1_train, X2_train, X3_train])\n",
    "X_test = np.vstack([X1_test, X2_test, X3_test])\n",
    "y_train = np.concatenate([y1_train, y2_train, y3_train])\n",
    "y_test = np.concatenate([y1_test, y2_test, y3_test])\n",
    "\n",
    "save_dist_data(X_train, X_test, y_train, y_test, 'syn3')\n",
    "\n",
    "fig = plt.figure()\n",
    "plot = fig.add_subplot(111, projection='3d')\n",
    "plot.scatter(X_train[:, 0], X_train[:, 1], X_train[:, 2], c='gray', s=1)\n",
    "plot.scatter(X_test[:, 0], X_test[:, 1], X_test[:, 2], c='red', s=1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "plot = fig.add_subplot(111, projection='3d')\n",
    "plot.scatter(X1[:,0], X1[:,1], X1[:,2], c='red', s=2)\n",
    "plot.scatter(X2[:,0], X2[:,1], X2[:,2], c='blue', s=2)\n",
    "plot.scatter(X3[:,0], X3[:,1], X3[:,2], c='green', s=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-Curve * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_c1 = [\n",
    "    {'n_samples':200, 't_center':0.25, 't_range':0.05, 'y_center':0.0, 'y_range':0.5, 'noise':0.01, 'gaussian': False},\n",
    "    {'n_samples':200, 't_center':0.4 , 't_range':0.04, 'y_center':0.0, 'y_range':0.5, 'noise':0.01, 'gaussian': False},\n",
    "    {'n_samples':200, 't_center':0.5 , 't_range':0.04, 'y_center':0.0, 'y_range':0.5, 'noise':0.01, 'gaussian': False},\n",
    "    {'n_samples':200, 't_center':0.6 , 't_range':0.04, 'y_center':0.0, 'y_range':0.5, 'noise':0.01, 'gaussian': False},\n",
    "    {'n_samples':200, 't_center':0.75, 't_range':0.05, 'y_center':0.0, 'y_range':0.5, 'noise':0.01, 'gaussian': False},\n",
    "]\n",
    "cluster_c2 = [\n",
    "    {'n_samples':150, 't_center':0.3, 't_range':0.17, 'y_center':-0.3, 'y_range':0.10, 'noise':0.01, 'gaussian': False},\n",
    "    {'n_samples':150, 't_center':0.7, 't_range':0.17, 'y_center':-0.3, 'y_range':0.10, 'noise':0.01, 'gaussian': False},\n",
    "    {'n_samples':150, 't_center':0.3, 't_range':0.17, 'y_center': 0.0, 'y_range':0.10, 'noise':0.01, 'gaussian': False},\n",
    "    {'n_samples':150, 't_center':0.7, 't_range':0.17, 'y_center': 0.0, 'y_range':0.10, 'noise':0.01, 'gaussian': False},\n",
    "    {'n_samples':150, 't_center':0.3, 't_range':0.17, 'y_center': 0.3, 'y_range':0.10, 'noise':0.01, 'gaussian': False},\n",
    "    {'n_samples':150, 't_center':0.7, 't_range':0.17, 'y_center': 0.3, 'y_range':0.10, 'noise':0.01, 'gaussian': False},\n",
    "]\n",
    "X=[]\n",
    "y=[]\n",
    "cluster_cs = cluster_c1 + cluster_c2\n",
    "for cluster in cluster_cs:\n",
    "    x=make_s_curve_clustered(**cluster)\n",
    "    X.append(x)\n",
    "    y.append(np.ones(x.shape[0]) * len(X))\n",
    "\n",
    "X=np.vstack(X)\n",
    "y=np.concatenate(y)\n",
    "\n",
    "save_prop_data(X, y, 'syn4')\n",
    "\n",
    "n_samples_single=sum([c['n_samples'] for c in cluster_c1])\n",
    "\n",
    "X1=X[:n_samples_single]\n",
    "y1=y[:n_samples_single]\n",
    "X2=X[n_samples_single:]\n",
    "X2 = Rotation.from_euler('z', 180, degrees=True).apply(X2)\n",
    "y2=y[n_samples_single:]\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, train_size=0.7, random_state=100, stratify=y1)\n",
    "X1_test[:, 2] *= 0.9\n",
    "X1_test[:, [1, 2]] += [ 0.2, -0.1]\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size=0.7, random_state=100, stratify=y2)\n",
    "X2_test[:, 2] *= 1.1\n",
    "X2_test[:, [1, 2]] += [-0.2, -0.1]\n",
    "\n",
    "X_train = np.vstack([X1_train, X2_train])\n",
    "X_test = np.vstack([X1_test, X2_test])\n",
    "y_train = np.concatenate([y1_train, y2_train])\n",
    "y_test = np.concatenate([y1_test, y2_test])\n",
    "\n",
    "save_dist_data(X_train, X_test, y_train, y_test, 'syn4')\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plot = fig.add_subplot(111, projection='3d')\n",
    "# plot.scatter(X_train[:, 0], X_train[:, 1], X_train[:, 2], c='gray')\n",
    "# plot.scatter(X_test[:, 0], X_test[:, 1], X_test[:, 2], c='red')\n",
    "# plt.show()\n",
    "\n",
    "fig=plt.figure()\n",
    "plot = fig.add_subplot(111, projection='3d')\n",
    "plot.scatter(X1[:,0], X1[:,1], X1[:,2], c=y1)\n",
    "plot.scatter(X2[:,0], X2[:,1], X2[:,2], c=y2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1330, 3)\n",
      "X_test shape:  (570, 3)\n"
     ]
    }
   ],
   "source": [
    "with h5.File(f'datasets/synth/syn4_dist.h5', 'r') as f:\n",
    "    X_train = f['E']['X0'][:]\n",
    "    y_train = f['E']['y0'][:]\n",
    "    X_test  = f['O']['X0'][:]\n",
    "    y_test  = f['O']['y0'][:]\n",
    "\n",
    "    print(\"X_train shape: \", X_train.shape)\n",
    "    print(\"X_test shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity: 30\n",
      "calc P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 00:23:46,252 - INFO - Precomputed initialization provided. Ignoring initalization-related parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to put X into GPU\n",
      "optimizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch 1000/1000 loss : -0.03602 time : 0.00391s: 100%|██████████| 1000/1000 [00:43<00:00, 22.78it/s]\n",
      "2024-10-10 00:24:35,464 - INFO - Start train for Visualize\n",
      "2024-10-10 00:24:49,705 - INFO - successfully compute approximate neighbor_graph\n",
      "2024-10-10 00:24:51,378 - INFO - Start Training for 1000 Epochs\n",
      "2024-10-10 00:24:51,379 - INFO - Experiment Configurations: \n",
      "Epochs: 1000 Batch Size: 133 \n",
      "Learning rate: 0.001000 Optimizer: adam\n",
      "\n",
      "2024-10-10 00:24:51,380 - INFO - Start Training for 1000 Epochs\n",
      "2024-10-10 00:25:09,612 - INFO - Epoch 100/1000, Train Loss: 1.85744, \n",
      "2024-10-10 00:25:27,901 - INFO - Epoch 200/1000, Train Loss: 1.86767, \n",
      "2024-10-10 00:25:47,614 - INFO - Epoch 300/1000, Train Loss: 1.89923, \n",
      "2024-10-10 00:26:08,428 - INFO - Epoch 400/1000, Train Loss: 1.92492, \n",
      "2024-10-10 00:26:29,284 - INFO - Epoch 500/1000, Train Loss: 1.91765, \n",
      "2024-10-10 00:26:50,095 - INFO - Epoch 600/1000, Train Loss: 1.82873, \n",
      "2024-10-10 00:27:10,870 - INFO - Epoch 700/1000, Train Loss: 1.87455, \n",
      "2024-10-10 00:27:31,448 - INFO - Epoch 800/1000, Train Loss: 1.94426, \n",
      "2024-10-10 00:27:51,576 - INFO - Epoch 900/1000, Train Loss: 1.84740, \n",
      "2024-10-10 00:28:09,956 - INFO - Epoch 1000/1000, Train Loss: 1.80089, \n",
      "c:\\Users\\60946\\dev_env\\lib\\site-packages\\umap\\parametric_umap.py:148: UserWarning: tensorflow_probability not installed or incompatible to current                 tensorflow installation. Setting global_correlation_loss_weight to zero.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParametricUMAP(batch_size=133, loss_report_frequency=1, optimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000002CF12158C10>)\n",
      "Thu Oct 10 00:28:09 2024 Construct fuzzy simplicial set\n",
      "Thu Oct 10 00:28:10 2024 Finding Nearest Neighbors\n",
      "Thu Oct 10 00:28:13 2024 Finished Nearest Neighbor Search\n",
      "Thu Oct 10 00:28:15 2024 Construct embedding\n",
      "28932/28932 [==============================] - 116s 4ms/step - loss: 0.1665\n",
      "42/42 [==============================] - 0s 965us/step\n",
      "Thu Oct 10 00:30:15 2024 Finished embedding\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from methods.methods import Methods\n",
    "\n",
    "methods = Methods(verbose=True)\n",
    "\n",
    "projectors = [\n",
    "    methods.get('pca'),\n",
    "    methods.get('kisomap'),\n",
    "    methods.get('ptsne22'),\n",
    "    methods.get('ktsne'),\n",
    "    methods.get('cdr'),\n",
    "    methods.get('pumap'),\n",
    "]\n",
    "\n",
    "projs = []\n",
    "\n",
    "for p in projectors:\n",
    "    p.fit(X_train)\n",
    "    proj=p.transform(X_train)\n",
    "    proj_test=p.transform_oos(X_test)\n",
    "    projs.append((proj, proj_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(len(projs) * 3, 3))\n",
    "for i,(proj, proj_test) in enumerate(projs):\n",
    "    plot = fig.add_subplot(1, len(projs), i + 1)\n",
    "    plot.scatter(proj[:,0], proj[:,1], c='gray', alpha=0.2, marker='o', s=3)\n",
    "    plot.scatter(proj_test[:,0], proj_test[:,1], c=y_test, alpha=0.7, marker='o', s=3)\n",
    "    plot.set_title(projectors[i].__class__.__name__)\n",
    "    plot.set_xticks([])\n",
    "    plot.set_yticks([])\n",
    "    plot.set_box_aspect(1.0)\n",
    "\n",
    "plt.show()\n",
    "# fig.show()\n",
    "# %matplotlib inline\n",
    "# %qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             _pca\n",
      "t        0.934663\n",
      "c        0.985649\n",
      "nh       0.731830\n",
      "lc       0.386216\n",
      "sd       0.950563\n",
      "tp      -0.023261\n",
      "sc       0.274576\n",
      "dsc      0.647368\n",
      "acc_oos  0.684211\n",
      "acc_e    0.681203\n"
     ]
    }
   ],
   "source": [
    "from metrics import Metrics\n",
    "metrics = Metrics()\n",
    "df=pd.DataFrame(index=metrics.available())\n",
    "for i,(proj, proj_test) in enumerate(projs):\n",
    "    metrics.update_metrics(X_train=X_train, X_train_Embedded=proj, X_test=X_test, X_test_Embedded=proj_test, y_train=y_train, y_test=y_test)\n",
    "    results=[]\n",
    "    for metric_name in metrics.available():\n",
    "        res,_ = metrics.run_single(metric_name)\n",
    "        results.append(res)\n",
    "    df[projectors[i].__class__.__name__] = results\n",
    "        \n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
